# üîÑ Processus de D√©veloppement - Workflow Odoo SA

**Processus INTRANSIGEANT bas√© sur les m√©thodes d'Odoo SA**

---

## üéØ Philosophie du Processus

> **"Quality is not negotiable, Speed comes from Process"** - Odoo SA

Odoo SA traite +50,000 commits par an avec **Z√âRO compromis** sur la qualit√©. Notre processus s'en inspire.

---

## üìã Vue d'Ensemble du Workflow

```mermaid
flowchart TD
    A[üìù Issue/Feature Request] --> B[üéØ Planning & Analysis]
    B --> C[üåø Create Feature Branch]
    C --> D[üíª Development + Tests]
    D --> E[üîç Self Review + Quality Check]
    E --> F[üì§ Pull Request]
    F --> G[üë• Code Review]
    G --> H{Review OK?}
    H -->|‚ùå Changes Needed| I[üîß Address Feedback]
    I --> G
    H -->|‚úÖ Approved| J[üß™ CI/CD Pipeline]
    J --> K{Tests Pass?}
    K -->|‚ùå Failed| L[üêõ Fix Issues]
    L --> J
    K -->|‚úÖ All Green| M[üöÄ Merge to Main]
    M --> N[üì¶ Deploy to Staging]
    N --> O[‚úÖ QA Validation]
    O --> P[üåê Deploy to Production]
```

---

## üéØ Phase 1 : Planning & Analysis (OBLIGATOIRE)

### Template de Planification

```markdown
# üìã Analyse Fonctionnelle - [FEATURE_NAME]

## üéØ Objectif M√©tier
**Probl√®me √† r√©soudre :** 
[Description claire du probl√®me business]

**Valeur apport√©e :**
[Impact m√©tier mesurable]

**Crit√®res de succ√®s :**
- [ ] Crit√®re 1 (m√©trique pr√©cise)
- [ ] Crit√®re 2 (m√©trique pr√©cise)
- [ ] Crit√®re 3 (m√©trique pr√©cise)

## üèóÔ∏è Analyse Technique

### Architecture Impact
- **Modules impact√©s :** 
- **D√©pendances :** 
- **Breaking changes :** Oui/Non
- **Migration n√©cessaire :** Oui/Non

### Estimation
- **Complexit√© :** Simple/Medium/Complex
- **Effort :** [X] jours d√©veloppeur
- **Tests :** [X] jours
- **Documentation :** [X] heures

### Risques Identifi√©s
| Risque | Impact | Probabilit√© | Mitigation |
|--------|--------|-------------|------------|
| Risk 1 | H/M/L  | H/M/L       | Action     |

## ‚úÖ Definition of Done
- [ ] Code impl√©ment√© selon standards
- [ ] Tests unitaires >80% couverture  
- [ ] Tests d'int√©gration complets
- [ ] Documentation mise √† jour
- [ ] Code review approuv√©
- [ ] CI/CD pipeline vert
- [ ] QA validation OK
- [ ] Performance benchmarks OK
```

### Checklist Pre-Development

```bash
#!/bin/bash
# scripts/pre-dev-check.sh

echo "üîç V√©rification pr√©-d√©veloppement..."

# 1. Branch principale √† jour
git fetch origin
if [ $(git rev-list HEAD..origin/main --count) -ne 0 ]; then
    echo "‚ùå Branch main pas √† jour. Faites: git pull origin main"
    exit 1
fi

# 2. Environnement clean
if [ -n "$(git status --porcelain)" ]; then
    echo "‚ùå Workspace pas clean. Commitez ou stashez vos changements"
    exit 1
fi

# 3. Tests passent
pytest || {
    echo "‚ùå Tests √©chouent sur main. R√©solvez avant de commencer"
    exit 1
}

echo "‚úÖ Pr√™t pour d√©veloppement"
```

---

## üåø Phase 2 : Feature Branch Creation

### Convention de Nommage STRICTE

```bash
# Format OBLIGATOIRE
feature/[module]-[description-courte]
bugfix/[module]-[bug-description]  
hotfix/[critical-issue]
refactor/[module]-[refactor-scope]

# ‚úÖ Exemples corrects
feature/auth-password-policy
feature/inventory-barcode-scanner
bugfix/payment-gateway-timeout
hotfix/security-user-bypass
refactor/database-query-optimization

# ‚ùå Interdits
feature/new-stuff
fix-bug
working-on-something
temp-branch
```

### Cr√©ation de Branch Standard

```bash
#!/bin/bash
# scripts/create-feature-branch.sh

if [ $# -ne 2 ]; then
    echo "Usage: $0 <type> <description>"
    echo "Types: feature|bugfix|hotfix|refactor"
    echo "Example: $0 feature auth-password-policy"
    exit 1
fi

TYPE=$1
DESCRIPTION=$2
BRANCH_NAME="${TYPE}/${DESCRIPTION}"

echo "üåø Cr√©ation de la branche: ${BRANCH_NAME}"

# V√©rification format
if ! [[ "$DESCRIPTION" =~ ^[a-z0-9-]+$ ]]; then
    echo "‚ùå Description doit √™tre en lowercase avec tirets uniquement"
    exit 1
fi

# Cr√©ation depuis main √† jour
git checkout main
git pull origin main
git checkout -b "$BRANCH_NAME"

echo "‚úÖ Branche cr√©√©e: ${BRANCH_NAME}"
echo "üìù N'oubliez pas de:"
echo "   1. Cr√©er issue GitHub li√©e"
echo "   2. Planifier les tests"
echo "   3. D√©finir les crit√®res de succ√®s"
```

---

## üíª Phase 3 : D√©veloppement STRICT

### Cycle de D√©veloppement TDD

```python
# 1. RED - √âcrire test qui √©choue
def test_user_password_validation_enforces_policy():
    # Arrange
    weak_password = "123456"
    
    # Act & Assert
    with pytest.raises(WeakPasswordError) as exc_info:
        user_service.create_user("test@example.com", "Test User", weak_password)
    
    assert "Password must contain at least 12 characters" in str(exc_info.value)

# 2. GREEN - Code minimal qui passe
class UserService:
    def create_user(self, email: str, name: str, password: str) -> User:
        if len(password) < 12:
            raise WeakPasswordError("Password must contain at least 12 characters")
        
        # Minimal implementation
        return User(email, name, password)

# 3. REFACTOR - Am√©liorer le code
class PasswordPolicy:
    def __init__(self):
        self.min_length = 12
        self.require_uppercase = True
        self.require_lowercase = True
        self.require_digits = True
        self.require_special_chars = True
    
    def validate(self, password: str) -> None:
        if len(password) < self.min_length:
            raise WeakPasswordError(f"Password must be at least {self.min_length} characters")
        
        if self.require_uppercase and not re.search(r'[A-Z]', password):
            raise WeakPasswordError("Password must contain uppercase letters")
        
        # ... autres validations

class UserService:
    def __init__(self, password_policy: PasswordPolicy):
        self._password_policy = password_policy
    
    def create_user(self, email: str, name: str, password: str) -> User:
        self._password_policy.validate(password)
        return User(email, name, password)
```

### Commits Atomiques OBLIGATOIRES

```bash
# ‚úÖ Commit progression logique
git add tests/test_password_policy.py
git commit -m "[TEST] auth: add password policy validation tests

Add comprehensive test suite for password strength validation
covering minimum length, character requirements, and edge cases.
Tests ensure business requirements for enterprise security."

git add src/core/services/password_policy.py
git commit -m "[ADD] auth: implement configurable password policy

Add PasswordPolicy class with configurable validation rules:
- Minimum length (default 12 characters)
- Character type requirements (upper, lower, digits, special)
- Extensible for future policy additions

Supports enterprise security compliance requirements."

git add src/core/services/user_service.py
git commit -m "[IMP] auth: integrate password policy in user creation

Enhance user creation workflow with password validation:
- Validate password strength before user creation
- Provide clear error messages for policy violations
- Maintain backward compatibility with existing API"
```

### Tests Obligatoires par Feature

```python
# tests/unit/core/services/test_user_service.py
class TestUserService:
    """Tests unitaires service utilisateur"""
    
    @pytest.fixture
    def user_service(self):
        password_policy = PasswordPolicy()
        user_repo = Mock()
        return UserService(password_policy, user_repo)
    
    def test_create_user_with_valid_password_succeeds(self, user_service):
        # Arrange
        email = "test@example.com"
        name = "Test User"  
        strong_password = "SecurePass123!@#"
        
        # Act
        user = user_service.create_user(email, name, strong_password)
        
        # Assert
        assert user.email == email
        assert user.name == name
        assert user.password_hash is not None

# tests/integration/test_user_workflow.py  
class TestUserWorkflow:
    """Tests d'int√©gration workflow complet"""
    
    def test_complete_user_registration_workflow(self, test_client, test_db):
        # 1. Cr√©ation utilisateur
        user_data = {
            "email": "integration@test.com",
            "name": "Integration Test",
            "password": "SecurePass123!@#"
        }
        
        response = test_client.post("/users", json=user_data)
        assert response.status_code == 201
        
        # 2. V√©rification en base
        user_id = response.json()["id"]
        saved_user = test_db.query(User).filter(User.id == user_id).first()
        assert saved_user is not None
        assert saved_user.email == user_data["email"]

# tests/performance/test_user_performance.py
class TestUserPerformance:
    """Tests de performance"""
    
    def test_user_creation_performance_under_100ms(self, user_service):
        start = time.time()
        
        user = user_service.create_user(
            "perf@test.com", 
            "Perf Test", 
            "SecurePass123!@#"
        )
        
        duration = time.time() - start
        assert duration < 0.1  # < 100ms
        assert user is not None
```

---

## üîç Phase 4 : Quality Gate INTRANSIGEANT

### Script de Validation Pre-PR

```bash
#!/bin/bash
# scripts/quality-gate.sh

set -e

echo "üõ°Ô∏è  QUALITY GATE - Standards Odoo SA"
echo "=================================="

# 1. Format Code (AUTO-FIX)
echo "üìù Auto-formatage du code..."
black src tests
isort src tests
echo "‚úÖ Code format√©"

# 2. Linting STRICT
echo "üîç Analyse qualit√© code..."
flake8 src tests --max-complexity=10 || {
    echo "‚ùå BLOQU√â: Erreurs de linting d√©tect√©es"
    echo "Corrigez TOUS les probl√®mes avant de continuer"
    exit 1
}

# 3. Type Checking STRICT
echo "üè∑Ô∏è  V√©rification types..."
mypy src --strict || {
    echo "‚ùå BLOQU√â: Erreurs de typage d√©tect√©es"
    echo "Type hints OBLIGATOIRES sur toutes les fonctions"
    exit 1
}

# 4. Security Scan ZERO TOLERANCE
echo "üîí Scan s√©curit√©..."
bandit -r src -ll || {
    echo "‚ùå BLOQU√â: Probl√®mes de s√©curit√© d√©tect√©s"
    echo "AUCUN probl√®me de s√©curit√© tol√©r√©"
    exit 1
}

# 5. Tests Coverage MINIMUM 80%
echo "üß™ Ex√©cution tests + couverture..."
pytest --cov=src --cov-report=term --cov-fail-under=80 || {
    echo "‚ùå BLOQU√â: Tests √©chou√©s ou couverture < 80%"
    echo "Ajoutez des tests pour atteindre le minimum requis"
    exit 1
}

# 6. Performance Benchmarks
echo "‚ö° Tests de performance..."
pytest tests/performance/ || {
    echo "‚ùå BLOQU√â: Tests de performance √©chou√©s"
    echo "Optimisez les performances avant merge"
    exit 1
}

# 7. Documentation Updated
echo "üìö V√©rification documentation..."
if [ -n "$(git diff --name-only HEAD..origin/main | grep '^src/' | head -1)" ]; then
    if [ -z "$(git diff --name-only HEAD..origin/main | grep '\.md$')" ]; then
        echo "‚ö†Ô∏è  ATTENTION: Code modifi√© mais pas de docs"
        echo "Pensez √† mettre √† jour la documentation si n√©cessaire"
    fi
fi

echo ""
echo "üéâ QUALITY GATE PASSED - Pr√™t pour Pull Request"
echo "Standards Odoo SA respect√©s ‚úÖ"
```

### M√©triques Qualit√© Automatiques

```python
# scripts/generate_metrics.py
import subprocess
import json
import os
from datetime import datetime
from pathlib import Path

class QualityMetrics:
    
    def __init__(self):
        self.project_root = Path.cwd()
        self.report_dir = self.project_root / "quality-reports"
        self.report_dir.mkdir(exist_ok=True)
    
    def generate_coverage_report(self) -> dict:
        """G√©n√®re rapport de couverture d√©taill√©"""
        result = subprocess.run(
            ['pytest', '--cov=src', '--cov-report=json', '--cov-report=html'],
            capture_output=True, text=True, check=True
        )
        
        with open('coverage.json') as f:
            coverage_data = json.load(f)
        
        return {
            'total_coverage': coverage_data['totals']['percent_covered'],
            'missing_lines': coverage_data['totals']['missing_lines'],
            'files_below_threshold': [
                file for file, data in coverage_data['files'].items() 
                if data['summary']['percent_covered'] < 80
            ]
        }
    
    def generate_complexity_report(self) -> dict:
        """Analyse complexit√© cyclomatique"""
        result = subprocess.run(
            ['radon', 'cc', 'src', '--json', '--min', 'C'],
            capture_output=True, text=True, check=True
        )
        
        complexity_data = json.loads(result.stdout)
        
        high_complexity_functions = []
        for file_path, functions in complexity_data.items():
            for func in functions:
                if func['complexity'] > 10:
                    high_complexity_functions.append({
                        'file': file_path,
                        'function': func['name'],
                        'complexity': func['complexity'],
                        'line': func['lineno']
                    })
        
        return {
            'high_complexity_count': len(high_complexity_functions),
            'high_complexity_functions': high_complexity_functions
        }
    
    def generate_technical_debt_report(self) -> dict:
        """Calcule la dette technique"""
        # TODO comments
        todo_result = subprocess.run(
            ['grep', '-r', '--include=*.py', 'TODO', 'src'],
            capture_output=True, text=True
        )
        todo_count = len(todo_result.stdout.splitlines()) if todo_result.returncode == 0 else 0
        
        # FIXME comments  
        fixme_result = subprocess.run(
            ['grep', '-r', '--include=*.py', 'FIXME', 'src'],
            capture_output=True, text=True
        )
        fixme_count = len(fixme_result.stdout.splitlines()) if fixme_result.returncode == 0 else 0
        
        # Duplicated code
        duplicate_result = subprocess.run(
            ['python', '-m', 'pycodestyle', '--statistics', 'src'],
            capture_output=True, text=True
        )
        
        return {
            'todo_count': todo_count,
            'fixme_count': fixme_count,
            'total_debt_markers': todo_count + fixme_count,
            'debt_level': 'HIGH' if (todo_count + fixme_count) > 10 else 'MEDIUM' if (todo_count + fixme_count) > 5 else 'LOW'
        }
    
    def generate_quality_score(self) -> dict:
        """Score qualit√© global (0-100)"""
        coverage = self.generate_coverage_report()
        complexity = self.generate_complexity_report()
        debt = self.generate_technical_debt_report()
        
        # Score calculation (Odoo-inspired)
        coverage_score = min(coverage['total_coverage'], 100)  # Max 100
        complexity_penalty = min(complexity['high_complexity_count'] * 5, 30)  # Max -30
        debt_penalty = min(debt['total_debt_markers'] * 2, 20)  # Max -20
        
        final_score = max(0, coverage_score - complexity_penalty - debt_penalty)
        
        quality_grade = (
            'A' if final_score >= 90 else
            'B' if final_score >= 80 else  
            'C' if final_score >= 70 else
            'D' if final_score >= 60 else 'F'
        )
        
        return {
            'score': final_score,
            'grade': quality_grade,
            'coverage_score': coverage_score,
            'complexity_penalty': complexity_penalty,
            'debt_penalty': debt_penalty,
            'details': {
                'coverage': coverage,
                'complexity': complexity,
                'technical_debt': debt
            }
        }
    
    def save_report(self, report: dict, filename: str):
        """Sauvegarde rapport avec timestamp"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.report_dir / f"{filename}_{timestamp}.json"
        
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2, default=str)
        
        print(f"üìä Rapport sauv√©: {report_file}")

if __name__ == "__main__":
    metrics = QualityMetrics()
    
    print("üìä G√©n√©ration rapport qualit√©...")
    quality_report = metrics.generate_quality_score()
    metrics.save_report(quality_report, "quality_score")
    
    print(f"\nüèÜ SCORE QUALIT√â: {quality_report['score']}/100 (Grade {quality_report['grade']})")
    print(f"üìà Couverture: {quality_report['details']['coverage']['total_coverage']:.1f}%")
    print(f"üî• Complexit√© haute: {quality_report['details']['complexity']['high_complexity_count']} fonctions")
    print(f"‚ö†Ô∏è  Dette technique: {quality_report['details']['technical_debt']['total_debt_markers']} marqueurs")
    
    if quality_report['grade'] in ['D', 'F']:
        print("\n‚ùå QUALIT√â INSUFFISANTE - Am√©lioration requise avant merge")
        exit(1)
    elif quality_report['grade'] == 'C':
        print("\n‚ö†Ô∏è  QUALIT√â ACCEPTABLE - Am√©lioration recommand√©e")
    else:
        print("\n‚úÖ EXCELLENTE QUALIT√â - Standards Odoo SA respect√©s")
```

---

## üì§ Phase 5 : Pull Request STRICT

### Template PR Obligatoire

```markdown
## üéØ Type de Changement
- [ ] [ADD] Nouvelle fonctionnalit√©
- [ ] [FIX] Correction de bug
- [ ] [IMP] Am√©lioration existante  
- [ ] [REF] Refactoring
- [ ] [TEST] Tests seulement
- [ ] [DOC] Documentation seulement

## üìù Description

### Probl√®me R√©solu
[Description claire du probl√®me business/technique r√©solu]

### Solution Impl√©ment√©e
[Explication technique de la solution choisie et pourquoi]

### Impact et Changements
[Modules/APIs/comportements impact√©s]

**‚ö†Ô∏è Breaking Changes:** Oui/Non
[Si oui, d√©tailler la migration n√©cessaire]

## üß™ Tests et Validation

### Coverage Report
```bash
# Coller r√©sultat de: pytest --cov=src --cov-report=term
```

### Tests Manuels Effectu√©s
- [ ] Test 1: [Sc√©nario test√©]
- [ ] Test 2: [Sc√©nario test√©]  
- [ ] Test 3: [Sc√©nario test√©]

### Performance Impact
[R√©sultats des benchmarks si applicable]

## ‚úÖ Checklist OBLIGATOIRE

### Qualit√© Code
- [ ] `./scripts/quality-gate.sh` passe ‚úÖ
- [ ] Coverage >= 80% sur nouveau code
- [ ] Aucun warning linting/typing
- [ ] Performance acceptable (si applicable)

### Standards Odoo SA
- [ ] Messages de commit respectent format `[TAG] module: description`
- [ ] Un commit = une modification logique
- [ ] Code suit les conventions architecture
- [ ] Documentation mise √† jour si n√©cessaire

### Tests
- [ ] Tests unitaires ajout√©s/mis √† jour
- [ ] Tests d'int√©gration si n√©cessaire
- [ ] Tests de performance si fonctionnalit√© critique
- [ ] Aucune r√©gression sur tests existants

### Review
- [ ] Auto-review effectu√© (own code review)
- [ ] TODO/FIXME nettoy√©s ou justifi√©s
- [ ] Pas de code comment√© inutile
- [ ] Logs/debug code supprim√©s

## üìä M√©triques Qualit√©

### Score Qualit√© Actuel
[Coller r√©sultat de: python scripts/generate_metrics.py]

### Comparaison Pre/Post
| M√©trique | Avant | Apr√®s | Œî |
|----------|-------|-------|---|
| Coverage | X%    | Y%    | +Z% |
| Complexit√© | X    | Y     | ¬±Z |
| Dette Tech | X    | Y     | ¬±Z |

## üîó Liens Connexes
- Issue: #XXX
- Documentation: [lien si applicable]
- Tickets connexes: #XXX, #YYY

---

## üìã Pour les Reviewers

### Points d'Attention Particuliers
[Zones sp√©cifiques n√©cessitant attention]

### Impact Environnements
- [ ] D√©veloppement: Test√© ‚úÖ
- [ ] Staging: √Ä d√©ployer
- [ ] Production: Migration n√©cessaire? Oui/Non

**‚è±Ô∏è Estimation Review:** [X] heures
```

### Crit√®res de Review NON-N√âGOCIABLES

```python
# scripts/review-checklist.py
"""
Checklist automatique de review - Standards Odoo SA
√Ä ex√©cuter AVANT approbation de PR
"""

import subprocess
import sys
from pathlib import Path

class ReviewChecklist:
    
    def check_commit_format(self) -> bool:
        """V√©rifie format des messages de commit"""
        result = subprocess.run(
            ['git', 'log', '--oneline', 'origin/main..HEAD'],
            capture_output=True, text=True
        )
        
        commit_messages = result.stdout.strip().split('\n')
        invalid_commits = []
        
        for commit in commit_messages:
            if commit:  # Skip empty lines
                message = commit.split(' ', 1)[1] if ' ' in commit else commit
                if not self._is_valid_commit_format(message):
                    invalid_commits.append(message)
        
        if invalid_commits:
            print("‚ùå COMMIT FORMAT INVALIDE:")
            for commit in invalid_commits:
                print(f"   ‚Ä¢ {commit}")
            print("\nFormat requis: [TAG] module: description")
            return False
        
        print("‚úÖ Format commits valide")
        return True
    
    def _is_valid_commit_format(self, message: str) -> bool:
        import re
        pattern = r'^\[(ADD|FIX|IMP|REF|REM|MERGE|TEST|DOC|I18N|CONF)\] [a-z_]+: .{10,49}$'
        return bool(re.match(pattern, message))
    
    def check_code_quality(self) -> bool:
        """V√©rifie qualit√© du code ajout√©"""
        try:
            # Linting
            subprocess.run(['flake8', 'src', 'tests'], check=True, 
                         capture_output=True)
            
            # Type checking
            subprocess.run(['mypy', 'src'], check=True, 
                         capture_output=True)
            
            # Security
            subprocess.run(['bandit', '-r', 'src'], check=True, 
                         capture_output=True)
            
            print("‚úÖ Qualit√© code valid√©e")
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"‚ùå PROBL√àME QUALIT√â CODE: {e}")
            return False
    
    def check_test_coverage(self) -> bool:
        """V√©rifie couverture de tests"""
        try:
            result = subprocess.run(
                ['pytest', '--cov=src', '--cov-report=json', '--cov-fail-under=80'],
                check=True, capture_output=True, text=True
            )
            
            print("‚úÖ Couverture tests >= 80%")
            return True
            
        except subprocess.CalledProcessError:
            print("‚ùå COUVERTURE TESTS INSUFFISANTE (<80%)")
            return False
    
    def check_breaking_changes(self) -> bool:
        """D√©tecte les breaking changes potentiels"""
        result = subprocess.run(
            ['git', 'diff', '--name-only', 'origin/main..HEAD'],
            capture_output=True, text=True
        )
        
        modified_files = result.stdout.strip().split('\n')
        critical_files = [
            'src/core/interfaces/',
            'src/adapters/web/api/',
            'requirements.txt',
            'pyproject.toml'
        ]
        
        breaking_changes = []
        for file in modified_files:
            if any(critical in file for critical in critical_files):
                breaking_changes.append(file)
        
        if breaking_changes:
            print("‚ö†Ô∏è  BREAKING CHANGES POTENTIELS:")
            for file in breaking_changes:
                print(f"   ‚Ä¢ {file}")
            print("\nV√©rifiez la r√©trocompatibilit√© et documentez les migrations")
        
        return True  # Pas bloquant mais informatif
    
    def check_performance_impact(self) -> bool:
        """V√©rifie l'impact performance si tests pr√©sents"""
        perf_tests = Path('tests/performance')
        if perf_tests.exists():
            try:
                subprocess.run(['pytest', 'tests/performance/'], 
                             check=True, capture_output=True)
                print("‚úÖ Tests performance OK")
                return True
            except subprocess.CalledProcessError:
                print("‚ùå R√âGRESSION PERFORMANCE D√âTECT√âE")
                return False
        else:
            print("‚ÑπÔ∏è  Pas de tests performance")
            return True
    
    def run_full_review_check(self) -> bool:
        """Ex√©cute la checklist compl√®te"""
        print("üîç REVIEW CHECKLIST - Standards Odoo SA")
        print("=" * 50)
        
        checks = [
            ("Format des commits", self.check_commit_format),
            ("Qualit√© du code", self.check_code_quality),
            ("Couverture tests", self.check_test_coverage), 
            ("Breaking changes", self.check_breaking_changes),
            ("Impact performance", self.check_performance_impact)
        ]
        
        all_passed = True
        for check_name, check_func in checks:
            print(f"\nüîç {check_name}...")
            if not check_func():
                all_passed = False
        
        print("\n" + "=" * 50)
        if all_passed:
            print("üéâ REVIEW CHECKLIST PASSED")
            print("‚úÖ PR pr√™t pour approbation")
            return True
        else:
            print("‚ùå REVIEW CHECKLIST FAILED") 
            print("üîß Corrections requises avant approbation")
            return False

if __name__ == "__main__":
    checker = ReviewChecklist()
    success = checker.run_full_review_check()
    sys.exit(0 if success else 1)
```

---

## ü§ñ Phase 6 : CI/CD Pipeline AUTOMATIS√â

### GitHub Actions - Pipeline Complet

```yaml
# .github/workflows/ci-cd.yml
name: CI/CD Pipeline - Odoo SA Standards

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

env:
  PYTHON_VERSION: "3.11"
  
jobs:
  quality-gate:
    name: üõ°Ô∏è Quality Gate
    runs-on: ubuntu-latest
    
    steps:
    - name: üì• Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for proper diff
    
    - name: üêç Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: üì¶ Install Dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
    
    - name: üîç Code Quality Check
      run: |
        echo "üîç Running quality gate..."
        ./scripts/quality-gate.sh
    
    - name: üìä Generate Quality Report
      run: |
        python scripts/generate_metrics.py > quality-report.txt
        cat quality-report.txt
    
    - name: üì§ Upload Quality Report
      uses: actions/upload-artifact@v3
      with:
        name: quality-report
        path: |
          quality-report.txt
          quality-reports/
          htmlcov/
    
    - name: üí¨ Comment Quality Score
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('quality-report.txt', 'utf8');
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: `## üìä Rapport Qualit√©\n\n\`\`\`\n${report}\n\`\`\``
          });

  security-scan:
    name: üîí Security Scan
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: üêç Setup Python  
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: üì¶ Install Security Tools
      run: |
        pip install bandit safety semgrep
    
    - name: üîç Bandit Security Scan
      run: |
        bandit -r src -f json -o bandit-report.json
        bandit -r src  # Human readable output
    
    - name: üîç Safety Dependencies Check
      run: safety check --json --output safety-report.json || true
    
    - name: üîç Semgrep Security Scan
      run: |
        semgrep --config=auto src --json --output=semgrep-report.json || true
    
    - name: üì§ Upload Security Reports
      uses: actions/upload-artifact@v3
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json  
          semgrep-report.json

  performance-tests:
    name: ‚ö° Performance Tests
    runs-on: ubuntu-latest
    if: contains(github.event.head_commit.message, '[PERF]') || github.event_name == 'pull_request'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: üêç Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: üì¶ Install Dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest-benchmark
    
    - name: ‚ö° Run Performance Tests
      run: |
        pytest tests/performance/ --benchmark-json=benchmark-report.json
    
    - name: üìä Performance Report
      run: |
        python -c "
        import json
        with open('benchmark-report.json') as f:
            data = json.load(f)
        print('üìä PERFORMANCE BENCHMARKS:')
        for test in data['benchmarks']:
            name = test['name']
            mean = test['stats']['mean']
            print(f'   ‚Ä¢ {name}: {mean:.3f}s avg')
        "
    
    - name: üì§ Upload Benchmark Report
      uses: actions/upload-artifact@v3
      with:
        name: performance-report
        path: benchmark-report.json

  integration-tests:
    name: üß™ Integration Tests
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: testdb
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
    - uses: actions/checkout@v4
    
    - name: üêç Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: üì¶ Install Dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest-xdist  # Parallel testing
    
    - name: üóÑÔ∏è Setup Test Database
      env:
        DATABASE_URL: postgresql://postgres:testpass@localhost:5432/testdb
      run: |
        python scripts/setup_test_db.py
    
    - name: üß™ Run Integration Tests
      env:
        DATABASE_URL: postgresql://postgres:testpass@localhost:5432/testdb
      run: |
        pytest tests/integration/ -v --tb=short -n auto
    
    - name: üìä Test Results Summary
      if: always()
      run: |
        echo "Integration tests completed"

  deploy-staging:
    name: üöÄ Deploy to Staging
    runs-on: ubuntu-latest
    needs: [quality-gate, security-scan, integration-tests]
    if: github.ref == 'refs/heads/develop' && github.event_name == 'push'
    
    environment:
      name: staging
      url: https://staging.yourapp.com
    
    steps:
    - uses: actions/checkout@v4
    
    - name: üöÄ Deploy to Staging
      run: |
        echo "üöÄ Deploying to staging environment..."
        # Your deployment script here
        ./scripts/deploy-staging.sh
    
    - name: üîç Health Check
      run: |
        echo "üîç Running health checks..."
        ./scripts/health-check.sh staging
    
    - name: üìß Notify Team
      if: always()
      run: |
        echo "üìß Notifying team of deployment status..."
        # Notification logic (Slack, email, etc.)

  deploy-production:
    name: üåê Deploy to Production
    runs-on: ubuntu-latest
    needs: [quality-gate, security-scan, integration-tests]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    environment:
      name: production
      url: https://yourapp.com
    
    steps:
    - uses: actions/checkout@v4
    
    - name: üåê Deploy to Production
      run: |
        echo "üåê Deploying to production..."
        ./scripts/deploy-production.sh
    
    - name: üîç Production Health Check
      run: |
        echo "üîç Production health check..."
        ./scripts/health-check.sh production
    
    - name: üìä Deployment Metrics
      run: |
        echo "üìä Recording deployment metrics..."
        python scripts/record_deployment_metrics.py

  notify-deployment:
    name: üì¢ Notify Deployment
    runs-on: ubuntu-latest
    needs: [deploy-staging, deploy-production]
    if: always()
    
    steps:
    - name: üì¢ Success Notification
      if: needs.deploy-production.result == 'success' || needs.deploy-staging.result == 'success'
      run: |
        echo "‚úÖ Deployment successful!"
        # Send success notification
    
    - name: üö® Failure Notification
      if: needs.deploy-production.result == 'failure' || needs.deploy-staging.result == 'failure'
      run: |
        echo "‚ùå Deployment failed!"
        # Send failure notification
```

---

## üìä Phase 7 : Monitoring & Feedback Loop

### M√©triques de D√©veloppement

```python
# scripts/dev_metrics_collector.py
import json
import subprocess
from datetime import datetime, timedelta
from typing import Dict, List
import sqlite3

class DevMetricsCollector:
    """Collecteur de m√©triques de d√©veloppement - Style Odoo SA"""
    
    def __init__(self, db_path: str = "dev_metrics.db"):
        self.db_path = db_path
        self._init_database()
    
    def _init_database(self):
        """Initialise la base de m√©triques"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS metrics (
                id INTEGER PRIMARY KEY,
                date TEXT NOT NULL,
                metric_type TEXT NOT NULL,
                metric_name TEXT NOT NULL, 
                value REAL NOT NULL,
                metadata TEXT
            )
        """)
        
        conn.commit()
        conn.close()
    
    def collect_git_metrics(self) -> Dict:
        """M√©triques Git (√† la Odoo SA)"""
        today = datetime.now().date()
        week_ago = today - timedelta(days=7)
        
        # Commits par jour
        result = subprocess.run([
            'git', 'log', '--since', str(week_ago), 
            '--pretty=format:%ad', '--date=short'
        ], capture_output=True, text=True)
        
        commits_by_day = {}
        for date_str in result.stdout.strip().split('\n'):
            if date_str:
                commits_by_day[date_str] = commits_by_day.get(date_str, 0) + 1
        
        # Commits par auteur
        result = subprocess.run([
            'git', 'shortlog', '-sn', '--since', str(week_ago)
        ], capture_output=True, text=True)
        
        commits_by_author = {}
        for line in result.stdout.strip().split('\n'):
            if line:
                parts = line.strip().split('\t')
                if len(parts) == 2:
                    count, author = parts
                    commits_by_author[author] = int(count)
        
        return {
            'commits_by_day': commits_by_day,
            'commits_by_author': commits_by_author,
            'total_commits_week': sum(commits_by_day.values())
        }
    
    def collect_quality_metrics(self) -> Dict:
        """M√©triques qualit√© code"""
        try:
            # Coverage
            cov_result = subprocess.run([
                'pytest', '--cov=src', '--cov-report=json'
            ], capture_output=True, text=True, check=True)
            
            with open('coverage.json') as f:
                cov_data = json.load(f)
            
            coverage = cov_data['totals']['percent_covered']
            
            # Complexit√©
            complexity_result = subprocess.run([
                'radon', 'cc', 'src', '--json'
            ], capture_output=True, text=True, check=True)
            
            complexity_data = json.loads(complexity_result.stdout)
            high_complexity_count = sum(
                1 for file_data in complexity_data.values()
                for func in file_data
                if func['complexity'] > 10
            )
            
            return {
                'test_coverage': coverage,
                'high_complexity_functions': high_complexity_count,
                'quality_score': max(0, coverage - (high_complexity_count * 5))
            }
            
        except Exception as e:
            print(f"Erreur collecte m√©triques qualit√©: {e}")
            return {}
    
    def collect_performance_metrics(self) -> Dict:
        """M√©triques performance (si benchmarks disponibles)"""
        try:
            result = subprocess.run([
                'pytest', 'tests/performance/', '--benchmark-json=bench.json'
            ], capture_output=True, text=True, check=True)
            
            with open('bench.json') as f:
                bench_data = json.load(f)
            
            benchmarks = {}
            for test in bench_data.get('benchmarks', []):
                benchmarks[test['name']] = {
                    'mean': test['stats']['mean'],
                    'stddev': test['stats']['stddev'],
                    'min': test['stats']['min'],
                    'max': test['stats']['max']
                }
            
            return {
                'benchmark_count': len(benchmarks),
                'benchmarks': benchmarks
            }
            
        except Exception:
            return {'benchmark_count': 0, 'benchmarks': {}}
    
    def store_metrics(self, metrics: Dict, metric_type: str):
        """Sauvegarde m√©triques en base"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        timestamp = datetime.now().isoformat()
        
        for metric_name, value in metrics.items():
            if isinstance(value, (int, float)):
                cursor.execute("""
                    INSERT INTO metrics (date, metric_type, metric_name, value, metadata)
                    VALUES (?, ?, ?, ?, ?)
                """, (timestamp, metric_type, metric_name, value, None))
            elif isinstance(value, dict):
                cursor.execute("""
                    INSERT INTO metrics (date, metric_type, metric_name, value, metadata) 
                    VALUES (?, ?, ?, ?, ?)
                """, (timestamp, metric_type, metric_name, 0, json.dumps(value)))
        
        conn.commit()
        conn.close()
    
    def generate_daily_report(self) -> Dict:
        """Rapport quotidien style Odoo SA"""
        git_metrics = self.collect_git_metrics()
        quality_metrics = self.collect_quality_metrics()
        perf_metrics = self.collect_performance_metrics()
        
        # Stockage en base
        self.store_metrics(git_metrics, 'git')
        self.store_metrics(quality_metrics, 'quality')
        self.store_metrics(perf_metrics, 'performance')
        
        report = {
            'date': datetime.now().isoformat(),
            'git': git_metrics,
            'quality': quality_metrics,
            'performance': perf_metrics,
            'summary': {
                'commits_today': git_metrics.get('total_commits_week', 0),
                'quality_score': quality_metrics.get('quality_score', 0),
                'test_coverage': quality_metrics.get('test_coverage', 0),
                'performance_tests': perf_metrics.get('benchmark_count', 0)
            }
        }
        
        return report
    
    def get_weekly_trends(self) -> Dict:
        """Tendances hebdomadaires"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        week_ago = (datetime.now() - timedelta(days=7)).isoformat()
        
        cursor.execute("""
            SELECT metric_type, metric_name, AVG(value) as avg_value
            FROM metrics 
            WHERE date >= ? AND value != 0
            GROUP BY metric_type, metric_name
        """, (week_ago,))
        
        trends = {}
        for row in cursor.fetchall():
            metric_type, metric_name, avg_value = row
            if metric_type not in trends:
                trends[metric_type] = {}
            trends[metric_type][metric_name] = avg_value
        
        conn.close()
        return trends

if __name__ == "__main__":
    collector = DevMetricsCollector()
    
    print("üìä G√©n√©ration rapport quotidien...")
    daily_report = collector.generate_daily_report()
    
    print(f"\nüìà RAPPORT D√âVELOPPEMENT - {daily_report['date'][:10]}")
    print("=" * 50)
    
    summary = daily_report['summary']
    print(f"üìù Commits semaine: {summary['commits_today']}")
    print(f"üèÜ Score qualit√©: {summary['quality_score']:.1f}/100")
    print(f"üìä Couverture tests: {summary['test_coverage']:.1f}%")
    print(f"‚ö° Tests performance: {summary['performance_tests']}")
    
    # Sauvegarde rapport
    with open(f"daily_report_{datetime.now().strftime('%Y%m%d')}.json", 'w') as f:
        json.dump(daily_report, f, indent=2)
    
    print(f"\nüíæ Rapport sauv√©: daily_report_{datetime.now().strftime('%Y%m%d')}.json")
```

### Dashboard M√©triques

```python
# scripts/generate_dashboard.py
import json
import sqlite3
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import pandas as pd
from pathlib import Path

class MetricsDashboard:
    """Dashboard m√©triques style Odoo SA"""
    
    def __init__(self, db_path: str = "dev_metrics.db"):
        self.db_path = db_path
        self.output_dir = Path("dashboard")
        self.output_dir.mkdir(exist_ok=True)
    
    def generate_quality_trends_chart(self):
        """Graphique tendances qualit√©"""
        conn = sqlite3.connect(self.db_path)
        
        df = pd.read_sql_query("""
            SELECT date, value 
            FROM metrics 
            WHERE metric_type = 'quality' AND metric_name = 'test_coverage'
            ORDER BY date DESC LIMIT 30
        """, conn)
        
        if not df.empty:
            df['date'] = pd.to_datetime(df['date'])
            
            plt.figure(figsize=(12, 6))
            plt.plot(df['date'], df['value'], marker='o', linewidth=2)
            plt.title('üìä √âvolution Couverture Tests (30 derniers jours)', fontsize=14, fontweight='bold')
            plt.xlabel('Date')
            plt.ylabel('Couverture (%)')
            plt.grid(True, alpha=0.3)
            plt.xticks(rotation=45)
            plt.tight_layout()
            
            plt.savefig(self.output_dir / 'quality_trends.png', dpi=300, bbox_inches='tight')
            plt.close()
        
        conn.close()
    
    def generate_commits_chart(self):
        """Graphique activit√© commits"""
        conn = sqlite3.connect(self.db_path)
        
        df = pd.read_sql_query("""
            SELECT date, value 
            FROM metrics 
            WHERE metric_type = 'git' AND metric_name = 'total_commits_week'
            ORDER BY date DESC LIMIT 30
        """, conn)
        
        if not df.empty:
            df['date'] = pd.to_datetime(df['date'])
            
            plt.figure(figsize=(12, 6))
            plt.bar(df['date'], df['value'], alpha=0.7, color='#2E86AB')
            plt.title('üìù Activit√© Commits (30 derniers jours)', fontsize=14, fontweight='bold')
            plt.xlabel('Date')
            plt.ylabel('Nombre de Commits')
            plt.xticks(rotation=45)
            plt.tight_layout()
            
            plt.savefig(self.output_dir / 'commits_activity.png', dpi=300, bbox_inches='tight')
            plt.close()
        
        conn.close()
    
    def generate_html_dashboard(self):
        """Dashboard HTML complet"""
        # R√©cup√©ration donn√©es r√©centes
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Derni√®res m√©triques
        cursor.execute("""
            SELECT metric_type, metric_name, value, date
            FROM metrics 
            WHERE date = (SELECT MAX(date) FROM metrics)
            ORDER BY metric_type, metric_name
        """)
        
        latest_metrics = {}
        for row in cursor.fetchall():
            metric_type, metric_name, value, date = row
            if metric_type not in latest_metrics:
                latest_metrics[metric_type] = {}
            latest_metrics[metric_type][metric_name] = value
        
        conn.close()
        
        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>üìä Dashboard M√©triques - Style Odoo SA</title>
    <style>
        body {{
            font-family: 'Segoe UI', sans-serif;
            margin: 0;
            padding: 20px;
            background: #f8f9fa;
        }}
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 30px;
        }}
        .metrics-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }}
        .metric-card {{
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        .metric-value {{
            font-size: 2em;
            font-weight: bold;
            color: #2E86AB;
        }}
        .metric-label {{
            color: #666;
            margin-top: 5px;
        }}
        .charts-section {{
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
        }}
        .chart-container {{
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        .status-good {{ color: #28a745; }}
        .status-warning {{ color: #ffc107; }}
        .status-danger {{ color: #dc3545; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>üìä Dashboard M√©triques de D√©veloppement</h1>
        <p>Standards Odoo SA - Derni√®re mise √† jour: {datetime.now().strftime('%d/%m/%Y %H:%M')}</p>
    </div>
    
    <div class="metrics-grid">
        <div class="metric-card">
            <div class="metric-value status-good">
                {latest_metrics.get('quality', {}).get('test_coverage', 0):.1f}%
            </div>
            <div class="metric-label">üìä Couverture Tests</div>
        </div>
        
        <div class="metric-card">
            <div class="metric-value status-good">
                {latest_metrics.get('quality', {}).get('quality_score', 0):.0f}/100
            </div>
            <div class="metric-label">üèÜ Score Qualit√©</div>
        </div>
        
        <div class="metric-card">
            <div class="metric-value">
                {latest_metrics.get('git', {}).get('total_commits_week', 0)}
            </div>
            <div class="metric-label">üìù Commits Semaine</div>
        </div>
        
        <div class="metric-card">
            <div class="metric-value status-warning">
                {latest_metrics.get('quality', {}).get('high_complexity_functions', 0)}
            </div>
            <div class="metric-label">üî• Fonctions Complexes</div>
        </div>
    </div>
    
    <div class="charts-section">
        <div class="chart-container">
            <h3>üìà Tendances Qualit√©</h3>
            <img src="quality_trends.png" alt="Tendances qualit√©" style="max-width: 100%;">
        </div>
        
        <div class="chart-container">
            <h3>üìù Activit√© Commits</h3>
            <img src="commits_activity.png" alt="Activit√© commits" style="max-width: 100%;">
        </div>
    </div>
    
    <div class="metric-card" style="margin-top: 30px;">
        <h3>üéØ Objectifs Odoo SA</h3>
        <ul>
            <li>Couverture tests: <strong>‚â•80%</strong> ‚úÖ</li>
            <li>Score qualit√©: <strong>‚â•85/100</strong> ‚úÖ</li>
            <li>Fonctions complexes: <strong>‚â§5</strong> ‚ö†Ô∏è</li>
            <li>Commits conformes: <strong>100%</strong> ‚úÖ</li>
        </ul>
    </div>
</body>
</html>
        """
        
        with open(self.output_dir / 'index.html', 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"üìä Dashboard g√©n√©r√©: {self.output_dir / 'index.html'}")

if __name__ == "__main__":
    dashboard = MetricsDashboard()
    
    print("üìä G√©n√©ration dashboard m√©triques...")
    dashboard.generate_quality_trends_chart()
    dashboard.generate_commits_chart()  
    dashboard.generate_html_dashboard()
    
    print("‚úÖ Dashboard complet g√©n√©r√©!")
    print(f"üåê Ouvrez: {dashboard.output_dir / 'index.html'}")
```

---

## üéØ Application Imm√©diate - Setup Complet

### 1. Scripts de Setup (15min)

```bash
#!/bin/bash
# scripts/setup-odoo-workflow.sh

echo "üöÄ Setup Workflow Odoo SA - Standards INTRANSIGEANTS"
echo "=================================================="

# 1. Structure des scripts
mkdir -p scripts hooks/.github/workflows

# 2. Hooks Git
cat > hooks/pre-commit << 'EOF'
#!/bin/bash
echo "üîç Pre-commit Quality Gate..."
./scripts/quality-gate.sh
EOF

cat > hooks/pre-push << 'EOF'  
#!/bin/bash
echo "üîç Pre-push Review Check..."
python scripts/review-checklist.py
EOF

chmod +x hooks/*

# 3. Installation hooks
cp hooks/* .git/hooks/

# 4. Configuration Git
git config core.hooksPath .git/hooks

# 5. Premier test
echo "‚úÖ Workflow Odoo SA install√©!"
echo "üß™ Test du quality gate..."
if ./scripts/quality-gate.sh; then
    echo "üéâ PR√äT! Standards Odoo SA activ√©s"
else
    echo "‚ö†Ô∏è  Corrections n√©cessaires avant premier commit"
fi
```

### 2. Template Premier Projet (10min)

```python
# src/core/models/__init__.py
"""
Core Business Models - Architecture Odoo SA
Mod√®les m√©tier purs, sans d√©pendances externes
"""

# src/core/services/__init__.py  
"""
Business Services - Orchestration Odoo SA
Logique applicative et workflows m√©tier
"""

# src/adapters/__init__.py
"""
External Adapters - Clean Architecture Odoo SA  
Interface avec syst√®mes externes (DB, API, etc.)
"""

# tests/unit/test_sample.py
import pytest

def test_sample_always_passes():
    """Test exemple pour valider setup"""
    assert True

class TestOdooStandards:
    """Tests validation standards Odoo SA"""
    
    def test_project_structure_exists(self):
        """V√©rifie structure projet standard"""
        import os
        required_dirs = [
            'src/core/models',
            'src/core/services', 
            'src/adapters',
            'tests/unit',
            'tests/integration'
        ]
        
        for dir_path in required_dirs:
            assert os.path.exists(dir_path), f"Directory missing: {dir_path}"
    
    def test_quality_scripts_exist(self):
        """V√©rifie pr√©sence scripts qualit√©"""
        import os
        required_scripts = [
            'scripts/quality-gate.sh',
            'scripts/review-checklist.py'
        ]
        
        for script_path in required_scripts:
            assert os.path.exists(script_path), f"Script missing: {script_path}"
```

### 3. Premi√®re Feature Standard (15min)

```bash
#!/bin/bash
# scripts/demo-first-feature.sh

echo "üéØ D√©monstration premi√®re feature - Standards Odoo SA"

# 1. Cr√©ation branche
git checkout -b feature/demo-user-model

# 2. Impl√©mentation TDD
cat > tests/unit/core/test_user_model.py << 'EOF'
import pytest
from src.core.models.user import User
from src.core.exceptions import ValidationError

class TestUser:
    def test_user_creation_with_valid_data_succeeds(self):
        user = User("test@example.com", "Test User")
        assert user.email == "test@example.com"
        assert user.name == "Test User"
    
    def test_user_creation_with_invalid_email_raises_error(self):
        with pytest.raises(ValidationError, match="Email invalide"):
            User("invalid-email", "Test User")
EOF

# 3. Impl√©mentation minimale
mkdir -p src/core/models src/core/exceptions

cat > src/core/exceptions.py << 'EOF'
class ValidationError(Exception):
    """Erreur de validation m√©tier"""
    pass
EOF

cat > src/core/models/user.py << 'EOF'
import re
from ..exceptions import ValidationError

class User:
    def __init__(self, email: str, name: str):
        if not email or '@' not in email:
            raise ValidationError("Email invalide")
        if not name or len(name.strip()) < 2:
            raise ValidationError("Nom invalide")
        
        self.email = email
        self.name = name.strip()
EOF

# 4. Tests et commit
pytest tests/unit/core/test_user_model.py
git add tests/unit/core/test_user_model.py
git commit -m "[TEST] user: add user model validation tests

Add comprehensive tests for User model creation covering:
- Valid data scenarios with proper email and name
- Invalid email format validation with clear error messages
- Business rule validation ensuring data integrity"

git add src/core/
git commit -m "[ADD] user: implement User model with validation

Add User domain model with strict validation rules:
- Email format validation ensuring @ symbol presence  
- Name validation requiring minimum 2 characters
- Clean architecture compliance with no external dependencies

Foundation for user management system following Odoo SA patterns."

echo "‚úÖ Premi√®re feature cr√©√©e selon standards Odoo SA!"
echo "üìã Prochaines √©tapes:"
echo "   1. Cr√©er PR vers develop"
echo "   2. Code review obligatoire" 
echo "   3. CI/CD pipeline validation"
echo "   4. Merge apr√®s approbation"
```

---

**üéØ R√âCAPITULATIF PROCESSUS**

| Phase | Dur√©e | Outils | Crit√®res Succ√®s |
|-------|-------|---------|-----------------|
| Planning | 2h | Issue template, Analysis doc | Definition of Done claire |
| Dev Branch | 5min | Git standards | Format naming respect√© |
| Development | Variable | TDD, Quality tools | Tests >80%, Standards OK |
| Quality Gate | 10min | Scripts automatis√©s | Tous checks verts |
| Pull Request | 30min | Template, Review | Approbation requise |
| CI/CD | 15min | GitHub Actions | Pipeline complet vert |
| Deploy | 10min | Automated scripts | Health checks OK |

**üõ°Ô∏è R√àGLE ABSOLUE :** Processus NON-N√âGOCIABLE. Odoo SA refuse tout raccourci. Nous aussi.

*Un processus respect√© = Code de qualit√© production.*